# 前言

> 本笔记参考[SpringCloud+RabbitMQ+Docker+Redis+搜索+分布式，史上最全面的springcloud微服务技术栈课程|黑马程序员Java微服务_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1LQ4y127n4)，感谢黑马！
>
> 视频资源教程下载：
> https://pan.baidu.com/s/169SFtYEvel44hRJhmFTRTQ
> 提取码：1234

## 微服务的概念

### 定义

​		维基百科对它的解释：

​		一种软件开发技术- 面向服务的体系结构（SOA）架构样式的一种变体，它提倡将**单一应用程序划分成一组小的服务**，服务之间互相协调、互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务间采用<u>轻量级</u>的通信机制互相沟通（通常是基于HTTP的RESTful API）。每个服务都围绕着具体业务进行构建，并且能够独立地部署到生产环境、类生产环境等。另外，应尽量避免统一的、集中式的服务管理机制，对具体的一个服务而言，应根据上下文，选择合适的语言、工具对其进行构建。

​		整个微服务的框架可以概括如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310141847.png)

### 特征

微服务有如下架构特征：

1.单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到**单一职责**。

2.自治：团队独立、技术独立、数据独立，独立部署和交付。

3.面向服务：服务提供统一标准的接口，与语言和技术无关。 

4.隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题。



​		总结下来就是，一个整体的系统中的各个模块可以做拆分，分成一个一个小的微服务模块每个微服务都是独立存在的，数据库也是按照微服务的划分独立存在的，最重要的是可以独立的部署到生产环境上。请求服务的方式可以通过http的形式进行请求。比如下图所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310142501.png)

### SpringCloud

​		Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，<u>都可以用**Spring Boot**的开发风格做到一键启动和部署</u>。Spring Cloud并没有重复制造轮子，它只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。

​		SpringCloud是目前国内使用最广泛的微服务框架。常用的微服务组件如下所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310142919.png)

​		我认为，最便捷的部分就是SpringCloud无缝衔接了当前主流方便的web框架Springboot，非常简单地就可以在Springboot的基础上开发SpringCloud微服务。Springboot和SpringCloud的兼容性如下所示：

|      Cloud版本      |         SpringBoot版本         |
| :-----------------: | :----------------------------: |
| 2020.0.x aka llford |             2.4.x              |
|       Hoxton        | 2.2.x,2.3.x(Starting with SR5) |
|      Greenwich      |             2.1.x              |
|      Finchley       |             2.0.x              |
|       Edgware       |             1.5.x              |
|       Dalston       |             1.5.x              |

​		本笔记使用的版本遵循黑马程序员娇嗔，使用的是Hoxton.SR10,SpringBoot版本是2.3.x版本。

## 服务拆分的例子

### 原则

​		既然微服务是将单体架构拆分成一个一个微服务，那么在服务拆分的时候需要遵循一些原则，原则如下：

1.不同微服务，不要重复开发相同业务。（**不要重复造轮子**）

2.微服务数据独立，不要访问其它微服务的数据库。

3.微服务可以将自己的业务**暴露为接口**，供其它微服务调用。

​		比如一个简单的商城案例，可以简单的分为如下的几个模块：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310143941.png)

### 订单、用户例子

​		教程中的例子有两个微服务，分别为订单的微服务和用户的微服务：order-service和user-service。他们对应的数据库是分别两个不同的数据库：cloud-user和cloud-order，结构和数据如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310145043.png)

​		在idea中的结构如下所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310145516.png)

​		其中两个服务如下所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310145745.png)

​		开启之后可以通过localhost:8080/order/101来请求订单号id为101的订单的详细信息，localhost:8081/user/1来请求查询用户id为1的用户的详细信息。不过Order的pojo类里还包含了User类，但是Order表里只存了User的id，我们就需要通过跨服务来请求User信息。

​		两个pojo类如下所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310150718.png)

​		用户查询的有关代码和查询结果如下所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310151159.png)

#### 跨服务请求

​		要求在查询订单的同时，根据订单中包含的userId查询出用户信息，一起返回。如下图所示

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310151442.png)

​		因此，我们需要在order-service中 向user-service发起一个http的请求，调用http://localhost:8081/user/{userId}这个接口。

​		步骤如下所示：

​		1.注册一个RestTemplate的实例到Spring容器（不要忘记了！）

​		2.修改order-service服务中的OrderService类中的queryOrderById方法，根据Order对象中的userId查询User

​		3.将查询的User填充到Order对象，一起返回

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310151950.png)

# Eureka注册中心

​		在上面的例子中我们在OrderService当中将跨请求的操作写死成localhost:8081端口，若我们的User的微服务有多个实例，且地址会发生改变的话，这么操作就不利于后续的维护拓展。

> order-service在发起远程调用的时候，该如何得知user-service实例的ip地址和端口？
>
> 有多个user-service实例地址，order-service调用时该如何选择？
>
> order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？

这个时候注册中心的作用就体现出来了!

## 基本介绍

​		Eureka是Netflix开发的**服务发现框架**，本身是一个基于**REST**的服务，主要用于定位运行在AWS域中的中间层服务，以达到**负载均衡**和**中间层服务故障转移**的目的。

​		SpringCloud将它集成在其子项目spring-cloud-netflix中，以实现SpringCloud的服务发现功能。Eureka包含两个组件：Eureka Server和Eureka Client。



## 作用

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310152551.png)

​		回答之前的各个问题。

一、order-service如何得知user-service实例地址？

​	获取地址信息的流程如下：

​	1.**服务注册**：user-service服务实例启动后，将自己的信息注册到eureka-server（Eureka服务端）。

​	2.eureka-server保存服务名称到服务实例地址列表的**映射关系**。

​	3.**服务发现**：order-service根据服务名称，拉取实例地址列表。这个叫**服务发现**或**服务拉取**。

------

二、order-service如何从多个user-service实例中选择具体的实例？

​		order-service从实例列表中利用**负载均衡算法**选中一个实例地址，向该实例地址发起远程调用。

------

三、order-service如何得知某个user-service实例是否依然健康，是不是已经宕机？

​	1.**心跳**：user-service会每隔一段时间（默认30秒）向eureka-server发起请求，报告自己状态。

​	2.当超过一定时间没有发送心跳时，eureka-server会认为微服务实例故障，将该实例从服务列表中剔除

​	3.order-service拉取服务时，就能将故障实例排除了

>  注意：一个微服务，既可以是服务提供者，又可以是服务消费者，因此eureka将服务注册、服务发现等功能统一封装到了eureka-client端

## 实践

​		把之前的例子应用到Eureka注册中心上，步骤如下所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310153126.png)

------

### 搭建Eureka服务端

​	Eureka服务端必须是一个独立的微服务，所以我们现在cloud-demo父工程下创建一个子模块，选择maven工程。

1.在依赖中导入eureka相关依赖：

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>
</dependency>
```

2.随后编写启动类，一定要添加一个@EnableEurekaServer注解，开启eureka的注册中心功能，并编写配置文件。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310160840.png)

3.启动服务之后访问该端口得到以下画面：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310161327.png)

可以看到eureka已经显示在其中了

### 注册服务

​		我们将user-service注册到eureka-server中。步骤如下

1.引入依赖：在user-service的pom文件中，引入下面的eureka-client依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
</dependency>
```

2.配置文件：在user-service中，修改application.yml文件，添加服务名称、eureka地址

```yaml
spring:
  application:
    name: userservice
eureka:
  client:
    service-url:
      defaultZone: http://127.0.0.1:10086/eureka
```

注册完毕之后，再访问eureka界面就可以看到已注册的服务了：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220310162819.png)

------

若想实现一个服务有多个机子呈现的话，可以使用idea里的copy configuration选项，再启动一个userservice。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251425027.png)

设置参数，将server.port改成8082

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251427591.png)

之后就会发现Services工具栏有一栏多的Not Started，其下正是UserApplication在8082端口的实例，启动它即可。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251428541.png)

启动之后再查看eureka界面就可以发现8082端口实例：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251429656.png)

### 发现服务

在eureka注册服务之后，这时请求服务就不用把主机地址写死了，只需要服务名称，就可以从eureka里拉取对应的服务。

将OrderService里跨服务请求改成服务拉取

步骤：

1.修改OrderService的代码，将url和端口改成付服务名

```java
//原来的版本是
//String url="http://127.0.0.1:8081/user/"+order.getUserId();
String url="http://userservice/user/"+order.getUserId();
```

2.在order-service项目的启动类OrderApplication中的RestTemplate添加负载均衡注解：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251434604.png)

这样就可以使用各种负载均衡策略，例如轮询、随机等等。

# Ribbon负载均衡

eureka的负载均衡是通过Ribbon来实现的

## 负载均衡原理

如图所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251440220.png)

## 修改负载均衡的策略

### 原理

IRule决定了负载均衡的策略，如果我们想修改负载均衡的策略，就可以通过IRule入手。

默认的规则实现的是ZoneAvoidanceRule根据zone选择服务列表然后轮询。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251452759.png)

其中各个负载均衡类对应的规则描述如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251452492.png)

### 步骤

方式一：

比如我们想修改order-service请求user-service时的负载均衡的策略，那么我就可以在order-service的OrderAppliction中重新创建一个IRule类，返回一个内置的负载均衡规则类。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251458879.png)

这样设置的话，order-service不管调用什么微服务，都是采用随机负载均衡规则。

------

方式二：

在配置文件方式修改，可以指定请求某个微服务时采用什么规则，如下图所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251500905.png)

## 饥饿加载

顾名思义：饥不择食，上来就先全部加载了。

Ribbon默认是采用懒加载，即第一次访问时才会去创建LoadBalanceClient，请求时间会很长。
而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面配置开启饥饿加载：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251507635.png)

# Nacos注册中心

与Eureka类似，但是比Eureka功能更加丰富，在国内受欢迎度较高，Nacos是阿里巴巴的产品，现在是SpringCloud里的组件了。

## nacos安装

去github上下载压缩包之后解压缩，解压路径不要有中文，之后通过在bin目录下cmd，命令输入：startup.cmd -m standalone。

默认登录用户名和密码是：

nacos

nacos

## Nacos服务分级存储模型

​	一个服务可以有多个实例，每个实例部署在不同的机房or地域，就形成了集群。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251558778.png)

​	所以在服务调用的时候，尽可能地选择本地集群的服务，因为跨集群调用延迟比较高。

## 环境隔离-namespace



![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251656286.png)

------

使用方法：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251658896.png)



![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251659344.png)

总结如下：

1.每个namespace都有唯一id

2.服务设置namespace时要写id而不是名称

3.不同namespace下的服务互相不可见

## 使用

### 服务注册到Nacos

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251529196.png)

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251530802.png)

### 配置集群

在服务的实例的application.yml里添加discovery下的cluster-name信息

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251621730.png)

再在nacos里查看

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251624724.png)

如果想三个实例在不同的集群，那么8081和8082再HZ集群上启动起来之后，修改cluster-name为SH，再启动8083即可，也可以通过修改参数来进行。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251629731.png)

可以看到有两个集群，HZ和SH：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251630707.png)

### NacosRule负载均衡

将OrderService配置到HZ集群中，测试**优先调用本地集群**的负载均衡规则。默认的规则没有选择同集群的即HZ的userservice。

------

步骤：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251638917.png)

第2步修改规则是在order-service下的application.yml里进行修改。注意还需要把之前在OrderAppliction.java里写的IRule给注释掉！

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251647179.png)

如果HZ集群的所有实例都停止工作了，nacos就会跨集群调用，这时会弹出警告信息，如下所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251649613.png)

### 根据权重负载均衡

实际部署中会出现这样的场景：
	服务器设备性能有差异，部分实例所在机器性能较好，另一些较差，我们希望性能好的机器承担更多的用户请求
	Nacos提供了权重配置来控制访问频率，**权重越大则访问频率越高**。

------

方法:

直接在Nacos控制台设置实例的权重值：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251651385.png)

若权重调整为0，则该实例就不会被访问到。

### 创建非临时实例

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251709046.png)

## 将配置交给nacos来管理

​	有些关键配置我们可以放在nacos中，在nacos里管理和修改后可以实现热更新，可以比较方便快捷。

注意：

​	1.不是所有的配置都适合放到配置中心，维护起来比较麻烦。

​	2.建议将一些关键参数，需要**运行时调整的参数**放到nacos配置中心，一般都是自定义配置。

### 在nacos中添加配置

step1:

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329093327.png)

step2:在弹出的表单中填写配置信息，注意Data ID的写法要规范！

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329093401.png)

点击发布之后就可以看到自己新添加的配置文件了：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329093518.png)

### 统一配置管理

​	微服务启动流程中读取配置的过程如下图所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329093628.png)

​	先读取bootstrap.yml再读取本地的配置文件application.yml

------

​	首先需要引入nacos的配置管理客户端依赖，在userservice下的pom.xml里添加如下依赖：

```xml
<!--nacos配置管理依赖-->
<dependency>    
    <groupId>com.alibaba.cloud</groupId>    
    <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
</dependency>
```

​	所以我们在resource文件夹下新创建一个bootstrap.yml，并写好相关配置：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329093821.png)

------

​	测试是否读取能读取到nacos的配置文件中的pattern.dateformat，通过Value注解进行测试，在UserController下进行修改：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329094143.png)

​	访问结果如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329094220.png)

### 实现热更新

​	假如我们想在nacos里修改了配置之后，修改的内容可以自动作用于微服务（userservice），那么可以热更新来实现，一共有两种方式实现：

第一种方式：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329094405.png)

------

第二种方式：

​	新创建一个专门用于获取配置的类，然后在这个类上使用@ConfigurationProperties注解

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329094622.png)

​	若有多个前缀，测试如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329095354.png)

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329095428.png)

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329095318.png)

​	若有多个前缀，则在prefix下依次用符号.来表示上下级关系即可。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329095659.png)



​	这两种方式可以混用，比如需要多级访问的时候，可以直接使用@Value注解来实现。

## 多环境配置共享

​	微服务启动时会从nacos读取多个配置文件：

1.[spring.application.name]-[spring.profiles.active].yaml，例如：userservice-dev.yaml

2.[spring.application.name].yaml，例如：userservice.yaml

​	无论profile如何变化，[spring.application.name].yaml这个文件一定会加载，因此**多环境共享配置**可以写入这个文件

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329134849.png)

## 不同微服务也可以共享配置

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329135207.png)

------

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329135223.png)

## 集群搭建

​	具体看链接内的压缩包：[nacos集群搭建.zip - 蓝奏云 (lanzouj.com)](https://wwz.lanzouj.com/iqXx7028m3ef)

​	上面打不开可以打开这个链接：[Gofile - Share file links quickly and easily](http://gofile.me/6TtvQ/cTEwrwbQS)

​	密码是nacos123

## 总结

### 原理细节

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202203251708335.png)

### 与eureka比较

共同点：

1.都支持服务注册和服务拉取

2.都支持服务提供者心跳方式做健康检测

------

不同点：

1.Nacos支持服务端**主动检测**提供者状态：临时实例采用**心跳模式**，非临时实例采用**主动检测模式**。

2.临时实例心跳不正常会被剔除，非临时实例则不会被剔除

3.Nacos支持服务列表变更的消息**推送模式**，服务列表更新更及时

4.Nacos集群默认采用AP方式（强调数据服务的可用性），当集群中存在非临时实例时，采用CP模式（强调数据的可靠性和一致性）；Eureka采用AP方式。

# http客户端Feign

​	可以通过Feign来实现优雅地通过http调用其他微服务。原先使用的RestTemplate发起远程调用会存在<u>代码可读性差</u>，<u>参数复杂UR难以维护</u>等缺点。

## 使用步骤

step1：

​	引入依赖

```xml
<dependency>    
    <groupId>org.springframework.cloud</groupId>   
    <artifactId>spring-cloud-starter-openfeign</artifactId> 
</dependency>
```

step2：

​	在order-service的启动类添加注解开启Feign的功能，因为是orderservice跨服务调用userservice里的方法，请求user数据。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329144551.png)

step3:(非最佳实践方法)

​	直接编写Feign客户端，创建cn.itcast.order.clients.UserClinet接口

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329145133.png)

（上图的接口名应该为UserClient，打错了...orz）

step4:

​	在OrderService代码里，将RestTemplate代码替换成Feign客户端代码

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220329145616.png)

------

Feign内部使用了Ribbon，实现了负载均衡

## 自定义配置

### 可配置项

Feign里有一些配置可以自定义，如下表所示：

| 类型                   | 作用             | 说明                                                         |
| ---------------------- | ---------------- | ------------------------------------------------------------ |
| **feign.Logger.Level** | 修改日志级别     | 包含四种不同的级别：NONE、BASIC、HEADERS、FULL（用的最多的） |
| feign.codec.Decoder    | 响应结果的解析器 | http远程调用的结果做解析，例如解析json字符串为java对象       |
| feign.codec.Encoder    | 请求参数编码     | 将请求参数编码，便于通过http请求发送                         |
| feign. Contract        | 支持的注解格式   | 默认是SpringMVC的注解                                        |
| feign. Retryer         | 失败重试机制     | 请求失败的重试机制，默认是没有，不过会使用Ribbon的重试       |

### 配置方法

方法一：在配置文件中修改

在order-service的application.yml文件中增加如下配置：

```yaml
feign:
  client:
    config:
      default: #这里用default就是全局配置，如果写某个服务名称，则是针对某个微服务的配置
        loggerLevel: FULL #日志级别
```

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204031805261.png)

------

方法二：java代码方式，需要先声明一个Bean

```java
public class FeignClientConfiguration{
    @Bean
    public Logger.Level feignLongLevel(){
        return Logger.Level.BASIC;
    }
}
```

（1）如果是全局配置，则把它放到@EnableFeignClients这个注解中：

```java
@EnableFeignClients(defaultConfiguration = FeignClientConfiguration.class)
```

(2)如果是局部配置，则把它放到@FeignClient这个注解中：

```java
@FeignClient(value = "userservice", configuration = FeignClientConfiguration.class)
```

BASIC级别的日志显示如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204031920862.png)

## 性能优化

### Feign底层的客户端实现

Feign底层默认使用的是URLConnection，它**不支持连接池**，影响性能与效率。而**Apache HttpClient**和**OKHttp**是支持连接池的。、

### 两个方向

1.日志级别最好使用basic或者none

2.使用连接池来代替默认的URLConnection

（1）引入依赖

```xml
<dependency>
    <groupId>io.github.openfeign</groupId>
    <artifactId>feign-httpclient</artifactId>
</dependency>
```

(2)配置application.yml文件

```yaml
feign: #通过配置文件来自定义Feign的配置
  client: # 用于配置Feign的日志的
    config:
      default: #这里用default就是全局配置，如果写某个服务名称，则是针对某个微服务的配置
        loggerLevel: NONE #日志级别
  httpclient: #httpclient的配置
    enabled: true
    max-connections: 200 # 最大连接数
    max-connections-per-route: 50 # 单个路径的最大连接数
```

## 最佳实践

​	最佳实践指的是企业在实际使用过程中总结出来的相对好用的Feign的使用方式。

### 继承方式

​	user-service里的controller中查询用户方法和order-service里的UserClient接口里的方法是一致的。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204031947181.png)

​	所以考虑给消费者的FeignClient和提供者的controller定义统一的父接口作为标准

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204031949663.png)

### 抽取方式

​	将FeignClient抽取为独立模块，并且把接口有关的POJO、默认的Feign配置都放到这个模块中，提供给所有消费者使用

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204031951020.png)



实现步骤：

1.首先创建一个module，命名为feign-api，然后引入feign的starter依赖

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-openfeign</artifactId>
</dependency>
```

2.将order-service中编写的UserClient、User、DefaultFeignConfiguration都复制到feign-api项目中

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032002256.png)

3.在order-service中删去之前的clients,config和pojo包下的User之后引入自己写的feign-api的依赖。

```xml
<dependency>
    <groupId>cn.itcast.demo</groupId>
    <artifactId>feign-api</artifactId>
    <version>1.0</version>
</dependency>
```

4.修改order-service中的所有与上述三个组件有关的import部分，改成导入feign-api中的包
5.还需要修改启动类，得让启动类能扫描到UserClinet，这有两种方式

（1）指定FeignClient所在包（批量引入）

```java
@EnableFeignClients(basePackages = "cn.itcast.feign.clients")
```

（2）指定FeignClient字节码（精准引入），可以是个数组，精准导入多个类

```java
@EnableFeignClients(clients = {UserClient.class})
```

# 统一网关Gateway

## 作用

​	我们的微服务在nacos里注册并且发现，用户如果直接能调取微服务的接口的话，存在安全隐患和权限问题，使用一个网关来对用户的请求做处理，用户先访问网关，又网关来处理微服务的调用问题，这样微服务的接口就不会暴露出来，只会在内部可见。

​	总结下来网关有这么几个作用：1.身份认证和权限校验2.服务路由、负载均衡3.请求限流

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032034529.png)

​	在SpringCloud中网关的实现主要包括两种：gateway和zuul，但是Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFlux，属于**响应式编程**的实现，具备**更好的性能**。

## 使用

### 网关的搭建

1.创建新的module，引入SpringCloudGateway的依赖和nacos的服务发现依赖：

```xml
<!--网关依赖-->
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>
<!--nacos服务发现依赖-->
<dependency>    
    <groupId>com.alibaba.cloud</groupId>   
    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId> 
</dependency>

```

2.随后写好gateway的启动类

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032039224.png)

### 编写路由配置及nacos地址

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032049347.png)

​	在resource文件夹下新建application.yml文件，填写以下配置：

```yaml
server:
  port: 10010 # 网关端口
spring:
  application:
    name: gateway # 服务名称
  cloud:
    nacos:
      server-addr: localhost:8848 # nacos地址
    gateway:
      routes: # 网关路由配置
        - id: user-service # 路由id，自定义，只要唯一即可
          # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址
          uri: lb://userservice # 路由的目标地址 lb就是loadbalance(负载均衡)，后面跟服务名称
          predicates: # 路由断言，也就是判断请求是否符合路由规则的条件
            - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求
        - id: order-service
          uri: lb://orderservice
          predicates:
            - Path=/order/**

```

​	配置完成后启动，访问网关端口10010，然后按照访问路径请求，发现请求的内容一致。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032046777.png)

------

网关通过路由表来想nacos注册中心拉取服务列表，进行负载均衡后发送具体的请求

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032047202.png)

## 断言工厂

​	我们在配置文件中写的断言规则只是字符串，这些字符串会被Predicate Factory读取并处理，转变为路由判断的条件。

​	例如Path=/user/**   是按照路径匹配，这个规则是由org.springframework.cloud.gateway.handler.predicate.**PathRoute**PredicateFactory类来处理的。像这样的断言工厂在SpringCloudGateway还有十几个。

​	要满足所用断言条件的时候，gateway才会进行相应的跳转。

具体如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032051298.png)

具体用法可以参照spring的官方文档：[Spring Cloud Gateway](https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/#gateway-request-predicates-factories)

比如我们想测试一下After工厂

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032056569.png)



![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032057313.png)

## 路由过滤器

### 工作流程

​	GatewayFilter是网关中提供的一种过滤器，可以对**进入网关**的<u>请求</u>和微服务**返回**的<u>响应</u>做处理：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032100948.png)

### 过滤工厂

​	Spring提供了31个过滤工厂，[Spring Cloud Gateway](https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/#gatewayfilter-factories)。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032102159.png)

### 使用

​	给所有进入userservice的请求添加一个请求头：Truth=itcast is freaking awesome!

​	实现方式：

​			在gateway中修改application.yml文件，给userservice的路由添加过滤器

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032107475.png)

​	随后在UserController中获取请求头并打印：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032108589.png)

​	请求/user/1，可以发现请求到了，不过访问/order/101的话打印出来的就是null

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032112390.png)

### 默认过滤器

​	如果要对所有的路由都生效，则可以将过滤器工厂写到default下

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032124362.png)



![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032123685.png)

### 全局过滤器

​	全局过滤器的作用也是处理**一切**进入网关的<u>请求</u>和微服务<u>响应</u>，与GatewayFilter的作用一样。
​	区别在于GatewayFilter通过配置定义，处理逻辑是固定的。而GlobalFilter的逻辑需要**自己写代码**实现。
定义方式是实现GlobalFilter接口。

```java
public interface GlobalFilter {
    /**
    *  处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理
    *
    * @param exchange 请求上下文，里面可以获取Request、Response等信息
    * @param chain 用来把请求委托给下一个过滤器 
    * @return {@code Mono<Void>} 返回标示当前过滤器业务结束
    */
    Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain);
}
```

------

使用：

​	定义全局过滤器，拦截并**判断用户身份**

​	需求：定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件：
​	1.参数中是否有authorization，
​	2.authorization参数值是否为admin
如果同时满足则放行，否则拦截



步骤：

在gateway包下创建AuthorizeFilter类，继承GlobalFilter

```java
package cn.itcast.gateway;

import org.springframework.cloud.gateway.filter.GatewayFilterChain;
import org.springframework.cloud.gateway.filter.GlobalFilter;
import org.springframework.core.annotation.Order;
import org.springframework.http.HttpStatus;
import org.springframework.stereotype.Component;
import org.springframework.util.MultiValueMap;
import org.springframework.web.server.ServerWebExchange;
import reactor.core.publisher.Mono;

@Order(-1) //这个值越小，过滤器优先级越高
@Component
public class AuthorizeFilter implements GlobalFilter {
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //1.获取请求参数
        MultiValueMap<String, String> params = exchange.getRequest().getQueryParams();
        //2.获取参数中的authorization参数
        String auth = params.getFirst("authorization");
        //3.判断参数值是否等于admin
        if ("admin".equals(auth)) {
            //4.是、放行
            return chain.filter(exchange);
            //5.否，拦截
        }
        exchange.getResponse().setStatusCode(HttpStatus.FORBIDDEN);
        return exchange.getResponse().setComplete();
    }
}
```

​	随后测试一下，发现直接访问并且没有带相应的参数时，会直接拒绝访问

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032149956.png)

​	带上authorization参数之后，就可以正常访问了：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032150983.png)

## 过滤器执行顺序

​	请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter

​	请求路由后，会将当前路由过滤器和DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，**排序后**依次执行每个过滤器，因为所有过滤器都可以转换为GatewayFilter，所以可以进行排序操作。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032154573.png)

​	每一个过滤器都必须指定一个int类型的order值，**order值越小，优先级越高，执行顺序越靠前**。GlobalFilter通过实现Ordered接口，或者添加@Order注解来指定order值，由我们自己指定。路由过滤器和defaultFilter的order由Spring指定，**默认是按照声明顺序从1递增**。

​	当过滤器的order值一样时，会按照 defaultFilter > 路由过滤器 > GlobalFilter的顺序执行。
可以参考下面几个类的源码来查看：

```
	org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator#getFilters()方法是先加载defaultFilters，然后再加载某个route的filters，然后合并。
	org.springframework.cloud.gateway.handler.FilteringWebHandler#handle()方法会加载全局过滤器，与前面的过滤器合并后根据order排序，组织过滤器链
```

## 跨域问题解决

跨域，域名不一致就是跨域，主要包括：

1.域名不同： www.taobao.com 和 www.taobao.org 和 www.jd.com 和 miaosha.jd.com

2.域名相同，端口不同：localhost:8080和localhost8081

产生的原因：浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题

解决方案：CORS

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/202204032201736.png)

# Docker

## 认识Docker

### Docker出现的原因

​	在项目部署时，大型项目组件较多，运行环境也较为复杂，部署时会碰到一些问题，比如依赖关系复杂，容易出现兼容性问题；开发、测试、生产环境有差异。

### Docker解决依赖兼容性的办法

​	那么Docker如何解决依赖的兼容问题呢？

​	1.Docker会将应用的Libs（函数库）、Deps（依赖）、配置与应用一起打包

​	2.将每个应用放到一个隔离**容器**去运行，避免互相干扰

### Docker的工作原理

​	首先先介绍系统内核，比如我们熟知的linux就是一种系统内核，但是像centOS和Ubuntu还有fedora，这些都是linux系统内核基础上开发的系统应用，针对项目部署上来，项目部署时先经过系统应用再到系统内核，再由系统内核操作计算机硬件。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406185549.png)

​	不同系统应用提供的不同函数接口就会导致一些兼容性问题。

------

​	Docker解决这个问题的方法如下：

​	1.Docker将用户程序与所需要调用的系统(比如Ubuntu)函数库一起打包

​	2.Docker运行到不同操作系统时，直接基于**打包的库函数**，借助于**操作系统的Linux内核**来运行

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406185838.png)

​	总结如下：

​	1.Docker如何解决大型项目依赖关系复杂，不同组件依赖的兼容性问题？

​	答：Docker允许开发中将应用、依赖、函数库、配置一起**打包**，形成可移植镜像。Docker应用运行在容器中，使用沙箱机制，相互**隔离**。

​	2.Docker如何解决开发、测试、生产环境有差异的问题

​	Docker镜像中包含完整运行环境，包括系统函数库，**仅依赖系统的Linux内核**，因此可以在任意Linux操作系统上运行。

### 与虚拟机的区别

​	虚拟机（virtual machine）是在操作系统中模拟硬件设备，然后运行另一个操作系统，比如在 Windows 系统里面运行 Ubuntu 系统，这样就可以运行任意的Ubuntu应用了。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406190106.png)

​	具体区别在于：Docker作为一个进程，而虚拟机是在操作系统中的一个操作系统，docker体积比虚拟机小，速度也比虚拟机快，所需要的资源也比虚拟机要少。

### Docker架构

1.镜像（Image）：Docker将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。

2.容器（Container）：镜像中的应用程序运行后形成的进程就是容器，只是Docker会给容器做隔离，对外不可见。每个容器都对互相不可见，运行在容器里的进程会认为只有它一个进程在运行。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406191211.png)

3.DockerHub:类似于github（代码托管平台），DockerHub是一个Docker镜像的托管平台。这样的平台称为Docker Registry。

4.Docker是一个CS架构的程序，具体看下图所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406191427.png)

## Docker安装

​	Docker安装于CentOS7 64 以上的系统，具体可以参照这篇文档：https://wwz.lanzouj.com/iXsz102qaotc，密码是c7jg，若打不开的话可以访问这个阿里云链接：https://www.aliyundrive.com/s/SGakPPLYizn

## 使用Docker

### 镜像相关命令

​	镜像名称一般分两部分组成：[repository]:[tag]。在没有指定tag时，默认是latest，代表最新版本的镜像。比如mysql:5.7和mysql:5.8是两个不同的镜像。



​	命令有：docker build，用于构建镜像，一般是针对本地的dockerfile镜像文件。docker pull表示从镜像服务器上拉取镜像，docker images查看镜像，docker rmi删除镜像，docker push推送镜像到服务器，docker saveb保存镜像为一个压缩包，docker load加载压缩包为镜像。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406202520.png)

​	可以使用docker --help查看帮助，比如想查看关于images命令具体的详细操作，可以使用docker images --help命令查看帮助。

------

使用案例：

1.pull命令

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406202713.png)

2.将刚刚pull下来的nginx镜像save出来

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406202944.png)

3.删除pull下来的nginx镜像，然后load刚刚save的nginx镜像。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406203147.png)

### 容器相关命令

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406205914.png)

其中docker ps默认查看的是正在运行的容器，如果带上参数a，就表示也查看停止的容器即docker ps -a

------

案例一：创建运行一个Nginx容器

步骤一：去docker hub查看Nginx的容器运行命令

```bash
docker run --name containerName -p 80:80 -d nginx
```

命令解读：

（1）docker run:创建并运行一个容器

（2）--name：给容器起一个名字

（3）-p：将宿主机端口与容器端口映射，冒号左侧是宿主机端口，右侧是容器端口

（4）-d：后台运行容器 

（5）nginx：镜像名称，例如nginx

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406210440.png)

运行结果，返回的字符串是全局唯一的用于标识容器的：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406211348.png)

随后使用docker ps查看容器信息：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406211508.png)

随后访问相应端口查看nginx页面，我的虚拟机的地址是192.168.10.130，直接浏览器访问该地址，得到以下结果：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406212132.png)

查看日志命令，带上-f参数就会实时显示更新日志数据：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406212255.png)

------

案例二：进入Nginx容器，修改HTML文件内容

步骤一：进入容器。进入我们刚刚创建的nginx容器的命令为：

```bash
docker exec -it mn bash
```

命令解读：

（1）docker exec：进入容器内部，执行一个命令

（2）-it：给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互

（3）mn：要进入的容器的名称

（4）bash：进入容器后执行的命令，bash是一个linux终端交互命令

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406220212.png)

步骤二：进入nginx的HTML所在目录 /usr/share/nginx/html

```bash
cd /usr/share/nginx/html
```

​	根据dockerhub官方文档可以得知nginx静态页面所在的目录为/usr/share/nginx/html，所以我们进入该目录，可看到有两个页面：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406220344.png)

步骤三：修改index.html

​	我们直接通过vi命令修改内容的话会报错，因为容器里不会默认安装vi命令，所以我们使用替换命令来进行修改。

```bash
sed -i 's#Welcome to nginx#思全全全#g' index.html
sed -i 's#<head>#<head><meta charset="utf-8">#g' index.html
```

可以看到修改成功：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220406220759.png)

注意：exec命令可以进入容器修改文件，但是在容器内修改文件是**不推荐**的。

### 数据卷相关命令

​	在上述案例二中，我们需要进入容器内部通过bash命令对html文件进行修改，比较麻烦，而且会有些问题，就是关于容器与数据耦合的问题：

1.不便于修改：当我们要修改Nginx的html内容时，需要进入容器内部修改，很不方便。

2.数据不可复用：在容器内的修改对外是不可见的。所有修改对新创建的容器是**不可复用**的。

3.升级维护困难：数据在容器内，如果要升级容器必然删除旧容器，所有数据都跟着删除了。即容器和数据深度绑定，容器没了那数据也会没有。

------

​	对上述问题，docker提出数据卷的概念，数据卷（volume）是一个**虚拟目录**，指向宿主机文件系统中的某个目录。容器的某个目录直接是一个数据卷，与宿主机上的某个目录互相绑定，当在宿主机相应目录下修改文件时，容器里的对应文件也会修改，同时当容器消失时，宿主机上的数据会被保留下来。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407092753.png)

------

​	数据卷操作的基本语法如下：

一、创建数据卷

```bash
docker volume [COMMAND]
```

​	docker volume命令是数据卷操作，根据命令后跟随的command来确定下一步的操作：

​	1.create    创建一个volume

​	2.inspect  显示一个或多个volume的信息

​	3.ls            列出所有的volume

​	4.prune    删除未使用的volume

​	5.rm          删除一个或多个指定的volume

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407093229.png)

二、挂载数据卷

​	运行容器时使用-v参数挂载数据卷。假设现在docker内部没有nginx容器，现在运行一个挂载数据卷的nginx容器。

```bash
docker run --name mn -p 80:80 -v html:/usr/share/nginx/html -d nginx
```

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407094453.png)

​	接着进入宿主机的数据卷目录

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407094739.png)

​	直接修改再访问即可。



注意：

​	1.如果docker run命令进行数据卷挂载时数据卷不存在，那么docker会自动的创建对应的数据卷出来。

​	2.可以直接基于目录挂载，当目录不存在时，docker会报错

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407100450.png)

可以具体参考：[docker数据卷（数据挂载） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/98950504)

### 镜像使用

​	目前我们都是使用的别人的镜像文件，那么我们如何自己打包一个镜像文件出来呢？我们先复习一下镜像的相关概念，接着会介绍有关镜像的相关结构。

一、镜像结构

​	镜像是将应用程序及其需要的系统函数库、环境、配置、依赖**打包**而成。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407101935.png)

二、自定义镜像

​	Dockerfile是一个文本文件，其中包含一个个的**指令**（Instruction），用指令来说明要执行什么操作系统来构建镜像。每个指令都会形成一层Layer。

| 指令       | 说明                                         | 示例                        |
| ---------- | -------------------------------------------- | --------------------------- |
| FROM       | 指定基础镜像                                 | FROM centos:6               |
| ENV        | 设置环境变量，可在后面指令中使用             | ENV key value               |
| COPY       | 拷贝本地文件到镜像的指定目录                 | COPY ./mysql-5.7.rpm /tmp   |
| RUN        | 执行Linux的shell命令，一般是安装过程的命令   | RUN yum install gcc         |
| EXPOSE     | 指定容器运行时监听的端口，是给镜像使用者看的 | EXPOSE 8080                 |
| ENTRYPOINT | 镜像中应用的启动命令，容器运行时调用         | ENTRYPOINT java -jar xx.jar |

更新详细语法说明，请参考官网文档： https://docs.docker.com/engine/reference/builder

案例一：基于Ubuntu镜像构建一个新镜像，运行一个java项目

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407102952.png)

[SpringCloud+RabbitMQ+Docker+Redis+搜索+分布式，史上最全面的springcloud微服务技术栈课程|黑马程序员Java微服务_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1LQ4y127n4?p=57)，P57有详细介绍

​	其中dockerfile文本文件里包含了相关的命令，具体如下所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407103354.png)

​	我们观察这个构建命令，可以观察得出大多数命令都是在配置jdk环境，那么如果我们在已经配置好jdk环境的镜像的基础上再构建，那么就会省事许多了。事实上就有，该镜像为java:8-alpine。



案例二：基于java:8-alpine镜像，将一个Java项目构建为镜像

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407103937.png)

​	在案例一的基础上，我们只需要将dockerfile修改成以下内容即可：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407104220.png)

注意：指定基础镜像也会被安装到docker中：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407104717.png)

## DockerCompose

### 定义

​	Docker Compose可以基于Compose文件帮我们快速的部署分布式应用，而**无需手动**一个个创建和运行容器！

​	Compose文件是一个文本文件，通过指令定义集群中的每个容器如何运行。比如Compose文件的内容可以是下面的形式：

```yaml
version: "3.8"
services:
  mysql:
    image: mysql:5.7.25
    environment:
     MYSQL_ROOT_PASSWORD: 123 
    volumes:
     - "/tmp/mysql/data:/var/lib/mysql"
     -  "/tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf"
  web:
    build: .
    ports:
     - "8090:8090"
```

​	DockerCompose的详细语法参考官网：https://docs.docker.com/compose/compose-file/

### 安装DockerCompose

具体可以参照这篇文档：https://wwz.lanzouj.com/iXsz102qaotc，密码是c7jg，若打不开的话可以访问这个阿里云链接：https://www.aliyundrive.com/s/SGakPPLYizn。

还可以参考这篇文章[(4条消息) docker-compose安装教程_w1990end的博客-CSDN博客_docker-compose 安装](https://blog.csdn.net/qq_33581509/article/details/115585426)

### 将之前写的cloud-demo利用DockerCompose部署

实现步骤：

1.查看课前资料提供的cloud-demo文件夹，里面已经编写好了docker-compose文件

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407141545.png)

2.修改docker-compose.yml，将数据库，nacos地址都改为本地的一些配置，比如版本号和密码。同时把idea客户端里写的项目的服务名都改成对应的（就是不要再用localhost加端口的形式了）

最外部的docker-compose.yml，内容如下：

```yaml
version: "3.2"

services:
  nacos: #nacos的具体配置
    image: nacos/nacos-server
    environment:
      MODE: standalone
    ports:
      - "8848:8848"
  mysql: #mysql所依赖的镜像的版本号
    image: mysql:8.0.11
    environment:
      MYSQL_ROOT_PASSWORD: root #mysql的root账户的密码
    volumes:
      - "$PWD/mysql/data:/var/lib/mysql"
      - "$PWD/mysql/conf:/etc/mysql/conf.d/"
  userservice:
    build: ./user-service #表示build的jar包在当前文件夹的user-service夏
  orderservice: #并不是每个微服务都对外暴露端口
    build: ./order-service
  gateway: #网关微服务应对外暴露端口
    build: ./gateway
    ports:
      - "10010:10010"
```

将user-service里的yml进行修改，其他微服务都做相应的修改

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407142825.png)

3.使用maven打包工具，将项目中的每个微服务都打包成为app.jar。

​	在pom.xml中最后一块build中的finalName玉树了最后打包出的jar包的名称：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407143130.png)

​	我们在每个需要打包的微服务的pom.xml中都填上这段代码。

​	随后使用maven工具对user-service微服务模块进行打包。打包出来的文件就在target目录下

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407143446.png)

​	打包完成：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407143640.png)

​	在打包order-service之前要先对父工程即cloud-demo进行clean和install才行，不然直接对order-service进行clean和package的话会报错！

4.将cloud-demo上传至虚拟机，利用docker-compose up -d来部署

部署结果：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407150757.png)

​	直接启动的话，nacos可能启动的慢从而导致依赖它的微服务报错，所以我们可以启动之后再用该命令restart一下：

```bash
docker-compose restart gateway userservice orderservice
```

​	如果想看对应微服务的相应日志，使用以下命令：

```bash
docker-compose logs -f xxx
```

xxx表示微服务名称

注意：这其中mysql版本还是指定用5.7.25，如果出现数据库拒绝访问，则可以参考下图里的操作：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407160908.png)

## 私有镜像仓库

​	搭建镜像仓库可以基于Docker官方提供的DockerRegistry来实现。

​	官网地址：https://hub.docker.com/_/registry

### 简化版镜像仓库

Docker官方的Docker Registry是一个基础版本的Docker镜像仓库，具备仓库管理的完整功能，但是没有图形化界面。

搭建方式比较简单，命令如下：

```sh
docker run -d \
    --restart=always \
    --name registry	\
    -p 5000:5000 \
    -v registry-data:/var/lib/registry \
    registry
```

命令中挂载了一个数据卷registry-data到容器内的/var/lib/registry 目录，这是私有镜像库存放数据的目录。

访问http://localhost:5000/v2/_catalog 可以查看当前私有镜像服务中包含的镜像

### 带有图形化界面的方式

​	使用DockerCompose部署带有图象界面的DockerRegistry，命令如下：

```sh
version: '3.0'
services:
  registry:
    image: registry
    volumes:
      - ./registry-data:/var/lib/registry
  ui:
    image: joxit/docker-registry-ui:static
    ports:
      - 8080:80
    environment:
      - REGISTRY_TITLE=传智教育私有仓库
      - REGISTRY_URL=http://registry:5000
    depends_on:
      - registry
```

​	还需要配置Docker信任地址，因为我们私服采用的是http协议，默认不被Docker信任，所以需要做一个配置：

```sh
# 打开要修改的文件
vi /etc/docker/daemon.json
# 添加内容：
"insecure-registries":["http://192.168.150.101:8080"]
# 重加载
systemctl daemon-reload
# 重启docker
systemctl restart docker
```

​	图形化界面的私有仓库搭建成功：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407162320.png)

​	推送镜像到私有镜像服务必须先tag，步骤如下：

1.重新tag本地镜像，名称前缀为私有仓库的地址：192.168.10.130:8080/

```bash
docker tag nginx:latest 192.168.10.130:8080/nginx:1.0 
```

2.推送镜像

```bash
docker push 192.168.10.130:8080/nginx:1.0 
```

3.拉取镜像

```bash
docker pull 192.168.10.130:8080/nginx:1.0 
```

推送镜像成功：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220407162759.png)

# MQ

## 同步通讯和异步通讯

一、同步通讯的优缺点：

​	1.优点：同步通讯可以实时获得结果

​	2.缺点：

​	（1）耦合度高：每次加入新的需求，都要修改原来的代码

​	（2）性能下降：调用者需要等待服务提供者响应，如果调用链过长则响应时间等于每次调用的时间之和。

​	（3）资源浪费：调用链中的每个服务在**等待响应**过程中，不能释放请求占用的资源，高并发场景下会极度**浪费系统资源**。

​	（4）级联失败：如果服务提供者出现问题，所有调用方都会跟着出问题，如同多米诺骨牌一样，迅速导致整个微服务群故障。可以想象成一个线上的蚂蚱。

二、异步通讯

​	异步调用常见实现就是事件驱动模式。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408153651.png)

​	各个微服务订阅事件，当事件发生之后，再进行处理。

​	1.优点：

​	（1）服务解耦：因为是事件驱动的，所以当我想再加功能的时候，就直接加就可以了。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408153851.png)

（2）性能提升，吞吐量提高：因为是异步的，不需要等结果出来再返回。

（3）服务没有强依赖，不担心级联失败问题：比如当订单服务出现错误的时候，不用担心仓储服务（假设仓储服务和订单服务没有强依赖关系）也不会正常工作。

（4）流量削峰：当流量非常大，事件发生的特别多的时候，事件可以在Broker内排队，因为各个服务是事件驱动的。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408154320.png)

2.缺点：

（1）依赖于Broker的可靠性、安全性、吞吐能力，如果Broker出现故障，则会导致问题。

（2）架构**复杂**了，业务没有明显的流程线，不好追踪管理，因为并不是线性流程，每个微服务的调用顺序可能并不唯一。

## MQ含义以及常用的MQ

​	MQ （MessageQueue），中文是消息队列，字面来看就是存放消息的队列。也就是事件驱动架构中的**Broker**。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408154558.png)

## RabbitMQ

​	RabbitMQ是实现了高级消息队列协议（AMQP）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而集群和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。

### 安装

> 可以参考这篇pdf，链接如下：https://wwz.lanzouj.com/igS2Q02u39fa 密码:8uv5

### 结构与概念

1.channel:操作MQ的工具

2.exchange：路由消息到队列中

3.queue：缓存消息

4.virtual host：虚拟主机，是对queue，exchange等资源的逻辑分组

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408163730.png)

### 实践

​	RabbitMQ官方给了几个案例：[RabbitMQ Tutorials — RabbitMQ](https://www.rabbitmq.com/getstarted.html)

​	目前有7个Demo。对应了几种不同的用法：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408164300.png)

------

​	我们先从最简单的HelloWorld案例开始，官方的HelloWorld是基于最基础的消息队列模型来实现的，只包括三个角色：

​	1.publisher：消息发布者，将消息发送到队列queue

​	2.queue：消息队列，负责接受并缓存消息

​	3.consumer：订阅队列，处理队列中的消息

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408164508.png)



案例实现：

​	有关资料：mq-demo.zip在这个链接下https://wwz.lanzouj.com/i8zHo02u9nvg，如果打不开的话可以用这个链接：http://gofile.me/6TtvQ/VLN9PYGmG

1.consumer的代码

```java
package cn.itcast.mq.helloworld;

import com.rabbitmq.client.*;
import java.io.IOException;
import java.util.concurrent.TimeoutException;
public class ConsumerTest {
    public static void main(String[] args) throws IOException, TimeoutException {
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost("192.168.150.101");//这里要改成虚拟机的ip地址
        factory.setPort(5672);//图形化界面的端口是15672，真正服务的端口是5672
        factory.setVirtualHost("/");
        factory.setUsername("itcast");
        factory.setPassword("123321");
        // 1.2.建立连接
        Connection connection = factory.newConnection();
        // 2.创建通道Channel
        Channel channel = connection.createChannel();
        // 3.创建队列
        String queueName = "simple.queue";
        channel.queueDeclare(queueName, false, false, false, null);
        // 4.订阅消息
        channel.basicConsume(queueName, true, new DefaultConsumer(channel){
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope,
                                       AMQP.BasicProperties properties, byte[] body) throws IOException {
                // 5.处理消息
                String message = new String(body);
                System.out.println("接收到消息：【" + message + "】");
            }
        });
        System.out.println("等待接收消息。。。。");
    }
}
```

​	consumer要设置接收到异步消息时的回调函数

2.publisher的代码：

```java
package cn.itcast.mq.helloworld;
import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;
import org.junit.Test;
import java.io.IOException;
import java.util.concurrent.TimeoutException;
public class PublisherTest {
    @Test
    public void testSendMessage() throws IOException, TimeoutException {
        // 1.建立连接
        ConnectionFactory factory = new ConnectionFactory();
        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码
        factory.setHost("192.168.150.101");
        factory.setPort(5672);
        factory.setVirtualHost("/");
        factory.setUsername("itcast");
        factory.setPassword("123321");
        // 1.2.建立连接
        Connection connection = factory.newConnection();
        // 2.创建通道Channel
        Channel channel = connection.createChannel();
        // 3.创建队列
        String queueName = "simple.queue";
        channel.queueDeclare(queueName, false, false, false, null);
        // 4.发送消息
        String message = "hello, rabbitmq!";
        channel.basicPublish("", queueName, null, message.getBytes());
        System.out.println("发送消息成功：【" + message + "】");
        // 5.关闭通道和连接
        channel.close();
        connection.close();
    }
}
```

接收和发送消息的流程如下图所示：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408170141.png)

## SpringAMQP

​	在abbitMQ基础上简化了操作，设计了一些模板类

### 概念

1.AMQP：

​	AMQP（高级消息队列协议），即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并**不受客户端/中间件不同产品，不同的开发语言等条件的限制**。

2.Spring AMQP是基于AMQP协议定义的一套API规范，提供了模板来发送和接收消息。包含两部分，其中spring-amqp是基础抽象，spring-rabbit是底层的默认实现。

SpringAmqp的官方地址：https://spring.io/projects/spring-amqp

### 实践

#### 简单队列

​	使用Spring AMQP来实现刚刚的HelloWorld的案例。

1.安装依赖，这里把依赖直接放到父工程mq-demo中

```xml
<!--AMQP依赖，包含RabbitMQ-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-amqp</artifactId>
</dependency>
```

2.在publisher中编写测试方法实现**发送消息逻辑**，向simple.queue发送消息

(1)在publisher服务中编写application.yml，添加mq连接信息：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408185201.png)

```yaml
spring:
  rabbitmq:
    host: 192.168.150.101 # 主机名
    port: 5672 # 端口
    virtual-host: / # 虚拟主机 
    username: itcast # 用户名
    password: 123321 # 密码
```

（2）在publisher服务中新建一个测试类，编写测试方法

```java
@RunWith(SpringRunner.class)
@SpringBootTest
public class SpringAmqpTest {
    @Autowired
    private RabbitTemplate rabbitTemplate;
    @Test
    public void testSimpleQueue() { 
        String queueName = "simple.queue";
        String message = "hello, spring amqp!";
        rabbitTemplate.convertAndSend(queueName, message);
    }
}
```

​	注意：这段代码不包括创建队列，所以如果没有运行第一个实现helloworld案例的话，需要手动在RabbitMQ里先加一个队列，随后运行publisher测试类就可以看到消息了。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408190058.png)

3.在consumer中编写**消费逻辑**，监听simple.queue

（1）在consumer服务中编写application.yml，添加mq连接信息：

```yaml
spring:
  rabbitmq:
    host: 192.168.150.101 # 主机名
    port: 5672 # 端口
    virtual-host: / # 虚拟主机 
    username: itcast # 用户名
    password: 123321 # 密码
```

（2）在consumer服务中新建一个类，编写消费逻辑：

```java
@Component
public class SpringRabbitListener {
    @RabbitListener(queues = "simple.queue")
    public void listenSimpleQueueMessage(String msg) throws InterruptedException {
        System.out.println("spring 消费者接收到消息 ：【" + msg + "】");
    }
}
```

​	这个SpringRabbitListener是Spring中的一个bean，所以我们吧consumer的spring启动类运行起来就可以了

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408191354.png)

​	注意：在RabbitMQ中消息一旦消费了，就消失了，即 阅后即焚，无法回溯

#### 工作队列

​	原理概念图，有多个消费者，可以提高消息处理速度，避免队列消息堆积。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408192925.png)

案例：模拟WorkQueue，实现一个队列绑定多个消费者

基本思路如下：

​	1.在publisher服务中定义测试方法，每秒产生50条消息，发送到simple.queue

```java
@Test
public void testWorkQueue() throws InterruptedException {
    // 队列名称
    String queueName = "simple.queue";
    // 消息
    String message = "hello, message__";
    for (int i = 0; i < 50; i++) {
        // 发送消息
        rabbitTemplate.convertAndSend(queueName, message + i);
        // 避免发送太快
        Thread.sleep(20);
    }
}
```

​	2.在consumer服务中定义两个消息监听者，都监听simple.queue队列。消费者1每秒处理50条消息，消费者2每秒处理10条消息

```java
@RabbitListener(queues = "simple.queue")
public void listenSimpleQueueMessage(String msg) throws InterruptedException {
    System.out.println("spring 消费者1接收到消息：【" + msg + "】");
    Thread.sleep(25);
}
@RabbitListener(queues = "simple.queue") 
public void listenSimpleQueueMessage2(String msg) throws InterruptedException {
    System.err.println("spring 消费者2接收到消息：【" + msg + "】");
    Thread.sleep(100);
}
```

​	理论上来说，1秒内就可以处理完所有消息，但是实际运行之后才发现用了5s左右，而且消费者1处理的是偶数消息，消费者2处理的是奇数消息。这是因为RabbitMQ有**预取机制**，会先分配下去拿过来发下去，分配时是平均分配的，所以会造成这种情况。

​	可以通过修改application.yml文件，设置preFetch这个值，可以控制预取消息的上限：

```yaml
spring:
  rabbitmq:
    host: 192.168.150.101 # 主机名
    port: 5672 # 端口
    virtual-host: / # 虚拟主机
    username: itcast # 用户名
    password: 123321 # 密码
    listener:
      simple:
        prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息
```

#### 发布订阅模型

​	发布订阅模式与之前案例的区别就是允许将同一消息发送给多个消费者。实现方式是加入了exchange（交换机）。常见的exchange类型有：①Fanout:广播②Direct:路由③Topic:话题

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408195239.png)

注意：exchange负责消息路由，而不是存储，**路由失败**则<u>消息丢失</u>。



一、Fanout交换机

​	Fanout Exchange 会将接收到的消息**广播**到每一个跟其绑定的queue

实现如下：利用SpringAMQP演示FanoutExchange的使用

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408195541.png)

​	1.在consumer服务中，利用代码声明队列、交换机，并将两者绑定，这里声明时使用的是Bean

```java
@Configuration
public class FanoutConfig {
    @Bean // 声明FanoutExchange交换机
    public FanoutExchange fanoutExchange() {
        return new FanoutExchange("itcast.fanout");
    }
    @Bean// 声明第1个队列
    public Queue fanoutQueue1() {
        return new Queue("fanout.queue1");
    }
    @Bean//绑定队列1到交换机
    public Binding fanountBinding1(Queue fanoutQueue1,FanoutExchange fanoutExchange){
        return BindingBuilder
                .bind(fanoutQueue1)
                .to(fanoutExchange);
    }
    @Bean// 声明第2个队列
    public Queue fanoutQueue2() {
        return new Queue("fanout.queue2");
    }
    @Bean//绑定队列1到交换机
    public Binding fanountBinding2(Queue fanoutQueue2,FanoutExchange fanoutExchange){
        return BindingBuilder
                .bind(fanoutQueue2)
                .to(fanoutExchange);
    }
}
```

2.在consumer服务的SpringRabbitListener类中，添加两个方法，分别监听fanout.queue1和fanout.queue2：

```java
@RabbitListener(queues = "fanout.queue1")
public void listenFanoutQueue1(String msg){
    System.out.println("spring 消费者接收到fanout.queue1的消息 ：【" + msg + "】");
}
@RabbitListener(queues = "fanout.queue2")
public void listenFanoutQueue2(String msg){
    System.out.println("spring 消费者接收到fanout.queue1的消息 ：【" + msg + "】");
}
```

3.在publisher服务的SpringAmqpTest类中添加测试方法

```java
@Test
public void testSendFanoutExchange(){
   String exchangeName="itcast.fanout";//交换机名称
   String message="hello,world";//消息
   //发送消息
   rabbitTemplate.convertAndSend(exchangeName,"",message);
}
```

总结：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408203445.png)

------

二、DirectExchange交换机

​	Direct Exchange 会将接收到的消息根据规则路由到指定的Queue，因此称为路由模式（routes）。

1.消息交换的步骤：

（1）每一个Queue都与Exchange设置一个BindingKey，每个queue都可以设置多个bindingKey

（2）发布者发送消息时，指定消息的RoutingKey

（3）Exchange将消息路由到BindingKey与消息RoutingKey**一致**的队列



2.案例：利用SpringAMQP演示DirectExchange的使用

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408204334.png)

（1）利用@RabbitListener声明Exchange、Queue、RoutingKey，使用注解的方法的话，直接SpringRabbitListener类里写如下两个方法即可，不需要再在config类里绑定了。

在consumer服务中，编写两个消费者方法，分别监听direct.queue1和direct.queue2

```java
@RabbitListener(bindings = @QueueBinding(
        value = @Queue(name = "direct.queue1"),
        exchange = @Exchange(name = "itcast.direct",type = ExchangeTypes.DIRECT),
        key = {"red","blue"}
))
public void listenDirectQueue1(String msg){
   System.out.println("spring 消费者接收到direct.queue1的消息 ：【" + msg + "】");
}

@RabbitListener(bindings = @QueueBinding(
      value = @Queue(name = "direct.queue2"),
      exchange = @Exchange(name = "itcast.direct",type = ExchangeTypes.DIRECT),
      key = {"red","yellow"}
))
public void listenDirectQueue2(String msg){
   System.out.println("spring 消费者接收到direct.queue2的消息 ：【" + msg + "】");
}
```

(2)在publisher中编写测试方法，向itcast. direct发送消息

```java
@Test
public void testSendDirectExchange(){
    String exchangeName="itcast.direct";//交换机名称
    String message="hello,blue";//消息
    //发送消息
    rabbitTemplate.convertAndSend(exchangeName,"blue",message);
}
```

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408205300.png)

总结：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408205456.png)

------

三、TopicExchange交换机

​	TopicExchange与DirectExchange类似，区别在于routingKey必须是多个单词的列表，并且以 **.** 分割。

Queue与Exchange指定BindingKey时可以使用通配符：

\#：代指0个或多个单词

*：代指一个单词

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408205956.png)

案例：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408210032.png)

步骤1：在consumer服务声明Exchange、Queue

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408210111.png)

步骤2：在publisher服务的SpringAmqpTest类中添加测试方法：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408210136.png)

### 消息转换器

​	直接发送object类型会被RabbitMQ通过jdk序列化进行传输，Spring的对消息对象的处理是由org.springframework.amqp.support.converter.MessageConverter来处理的。而默认实现是SimpleMessageConverter，基于JDK的ObjectOutputStream完成序列化。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408210533.png)

​	但是默认的jdk序列化有一些缺点，消耗大，而且可能有注入风险。



​	如果要修改只需要定义一个MessageConverter 类型的Bean即可。推荐用JSON方式序列化，步骤如下：

1.我们在publisher服务引入依赖

```xml
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
</dependency>
```

2.我们在publisher服务声明MessageConverter：

```java
@Bean
public MessageConverter jsonMessageConverter(){
    return new Jackson2JsonMessageConverter(); 
}
```

3.我们在consumer服务引入Jackson依赖（类似第一步）

4.我们在consumer服务定义MessageConverter：

```java
@Bean
public MessageConverter jsonMessageConverter(){
    return new Jackson2JsonMessageConverter(); 
}
```

4.然后定义一个消费者，监听object.queue队列并消费消息：

```java
@RabbitListener(queues = "object.queue")
public void listenObjectQueue(Map<String, Object> msg) {
    System.out.println("收到消息：【" + msg + "】"); 
}
```

运行结果，以json格式的话，可读性就比较高了。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408211322.png)

总结：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220408211054.png)

# Elasticsearch

## 介绍

​	Elasticsearch是一个基于Lucene的搜索服务器。它提供了一个**分布式**多用户能力的全文搜索引擎，**基于RESTful web接口**。Elasticsearch是用**Java**语言开发的，并作为Apache许可条款下的开放源码发布，是一种流行的企业级搜索引擎。

​	Elasticsearch用于云计算中，能够达到**实时搜索**，<u>稳定</u>，<u>可靠</u>，<u>快速</u>，安装使用方便。官方客户端在Java、.NET（C#）、PHP、Python、Apache Groovy、Ruby和许多其他语言中都是可用的。根据DB-Engines的排名显示，Elasticsearch是**最受欢迎**的企业搜索引擎，其次是Apache Solr，也是基于Lucene。

​	Elasticsearch结合kibana、Logstash、Beats，也就是elastic stack（ELK）。被广泛应用在日志数据分析、实时监控等领域。而Elasticsearch是elastic stack（elastic技术栈）的核心，负责存储、搜索、分析数据。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409104857.png)

------

发展历程：

​	ElasticSearch是基于Lucene的，那么Lucene是什么呢？

​	Lucene是一个**Java语言**的搜索引擎类库，是Apache公司的顶级项目，由DougCutting于1999年研发。

​	官网地址：https://lucene.apache.org/ 。

​	Lucene的优势：①易拓展 ②高性能（基于倒排索引）

​	劣势：①只限于Java语言开发 ②学习曲线陡峭 ③不支持水平拓展

​	那么相对于lucene，elasticsearch具备的优势有：①支持分布式，可水平拓展 ②支持Restful接口，**可被任何语言调用**

## 正向索引与倒排索引

​	我们之前在mysql中，用的就是正向索引（可以简称为索引）。正向索引是以**关键字**为主码，查询时需要**遍历每一个文件**。每个文件都对应一个文件ID，文件内容被表示为一串关键词的集合。实际上在搜索引擎索引库中，关键词也已经转换为关键词ID。这样的数据结构就称为正向索引。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409111259.png)

​	假如我们搜索手机，那么在正向索引技术里面，就会逐条扫描记录，把title中包含手机的记录存到结果集中。

------

一、词条、文档、词条字典以及倒排列表	

​	倒排索引使用了文档和词条的概念，文档（document）：每条数据就是一个文档；词条（term）：文档按照语义分成的词语。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409111648.png)

​	elasticsearch是面向文档存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被**序列化**为json格式后存储在elasticsearch中。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409112038.png)

还有词条词典和倒排列表的概念如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409111900.png)

二、索引与映射

​	索引（index）：相同类型的文档的集合；映射（mapping）：索引中文档的字段约束信息，类似表的结构约束。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409112305.png)

​	

## 与Mysql的对比

一、概念对比

| MySQL  | Elasticsearch | 说明                                                         |
| ------ | ------------- | :----------------------------------------------------------- |
| Table  | Index         | 索引(index)，就是文档的集合，类似数据库的表(table)           |
| Row    | Document      | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 |
| Column | Field         | 字段（Field），就是JSON文档中的字段，类似数据库中的列（Column） |
| Schema | Mapping       | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） |
| SQL    | DSL           | DSL是elasticsearch提供的JSON风格的请求语句，用来操作elasticsearch，实现CRUD |

​	SQL通过connection发送，而DSL只需要通过http请求发送即可，所以DSL不受语言的限制。

二、架构

Mysql擅长**事务类**（事务的ACID原则）型操作，可以确保数据的安全和一致性；

Elasticsearch擅长海量数据的搜索、分析、计算。

## 使用

### 安装Elasticsearch

​	参考这篇pdf：https://wwz.lanzouj.com/ieCAK02vrnsh  密码是：hsn1；若打不开则点击这个链接：http://gofile.me/6TtvQ/xA39x1Lkr 

es7.12.1的镜像：http://gofile.me/6TtvQ/09DpNsxtK

kibana的镜像：http://gofile.me/6TtvQ/0YDiefAd7

### 分词器

​	es在创建倒排索引时需要对文档分词；在搜索时，需要对用户输入内容**分词**。但默认的分词规则对中文处理并**不友好**。比如对“我是一个大帅哥”进行分词，我们可以在kibana的DevTools中提交POST请求进行测试：

```json
POST /_analyze
{
  "analyzer": "standard",
  "text": "我是一个大帅哥"
}
```

​	这里的/_analyze是请求路径，省略了本机的ip地址（因为有kibana帮我们补充）。请求参数是json风格的：analyzer是分词器的类型，text是要分词的内容。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409183045.png)

​	默认的分词器把这句话里的每个字都分出来了，可见不是很合理。

------

​	那么我们处理对中文进行分词操作的时候，一般会使用IK分词器。https://github.com/medcl/elasticsearch-analysis-ik  ，安装教程参考《安装elasticsearch.md》。其中所需的压缩包可以见：https://wwz.lanzouj.com/iziBH02wkszi或者http://gofile.me/6TtvQ/INfQAifON 



​	如果查看日志发现有这个情况，我查了一下好像没大碍，似乎是es在恢复数据，我自己提交ik分词器请求也正常返回。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409184557.png)

​	IK分词器有两种模式：①ik_smart：最少切分，粗粒度 ②ik_max_word：最细切分，细粒度（简而言之就是会分更多的词出来）；那么我们使用ik_smart对刚刚的话进行切分。

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409184822.png)

#### 拓展词典

​	有些词语可能不存在于原有的词汇列表。比如“奥利给”。所以我们的词汇也需要不断的更新，IK分词器提供了扩展词汇的功能。

​	要拓展ik分词器的词库，只需要修改一个ik分词器目录中的config目录中的IkAnalyzer.cfg.xml文件：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
	<comment>IK Analyzer 扩展配置</comment>
	<!--用户可以在这里配置自己的扩展字典 -->
	<entry key="ext_dict">ext.dic</entry>
	 <!--用户可以在这里配置自己的扩展停止词字典-->
	<entry key="ext_stopwords">stopword.dic</entry>
	<!--用户可以在这里配置远程扩展字典 -->
	<!-- <entry key="remote_ext_dict">words_location</entry> -->
	<!--用户可以在这里配置远程扩展停止词字典-->
	<!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>
```

​	然后新建ext.dic和stopword.dic，并且编辑

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409190839.png)

​	重启es后进行测试：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220409191102.png)

### 索引库操作：DSL语法

#### mapping属性

​	mapping是对索引库中文档的约束，常见的mapping属性包括：

​	1.type：字段数据类型，常见的简单类型有：

​			（1）字符串：text（可分词的文本）、keyword（精确值，即不可分的，例如：品牌、国家、ip地址），比如ip地址就不用再继续分词了

​			（2）数值：long、integer、short、byte、double、float

​			（3）布尔：boolean

​			（4）日期：date

​			（5）对象：object

​	2.analyzer：使用哪种分词器

​	3.properties：该字段的子字段

​	4.index：是否创建倒排索引，默认为true

注意：在ES中没有数组的概念，但是一个字段可以有多个值，比如下图中的score

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410170054.png)

#### 创建索引库

​	若要创建上图的索引，命令如下所示：创建一个名为heima的索引表

```json
PUT /heima
{
  "mappings": {
    "properties": {
      "info":{
        "type": "text",
        "analyzer": "ik_smart"
      },
      "email":{
        "type": "keyword",
        "index": "false"
      },
      "name":{
        "type":"object",
        "properties": {
          "firstName": {
            "type": "keyword"
          },
          "lastName":{
             "type":"keyword"
          }
        }
      }
    }
  }
}
```

结果：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410184337.png)

#### 查看、删除索引库

1.查看

​	GET /索引库名称

比如：GET /heima    得到的结果如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410184949.png)

2.删除

​	DELETE /索引库名 

#### 修改索引库

​	索引库和mapping一旦创建无法修改，但是可以添加新的字段，语法如下：

```json
PUT /索引库名/_mapping
{
  "properties": {
    "新字段名":{
      "type": "integer"
    }
  }
}
```

比如：

```json
PUT /heima/_mapping
{
  "properties":{
    "age":{
      "type":"integer"
    }
  }
}
```

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410185203.png)

### 文档操作：DSL语法

​	文档可以简单理解为sql中的一条记录。

#### 新增文档

```json
POST /索引库名/_doc/文档id
{
    "字段1": "值1",
    "字段2": "值2",
    "字段3": {
        "子属性1": "值3",
        "子属性2": "值4"
    },
    // ...
}
```

示例：

```json
POST /heima/_doc/1
{
    "info": "黑马程序员Java讲师",
    "email": "zy@itcast.cn",
    "name": {
        "firstName": "云",
        "lastName": "赵"
    }
}
```

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410185419.png)

#### 查看文档

​	GET /索引库名/_doc/文档id 

示例：GET /heima/_doc/1 

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410185659.png)

#### 删除文档

​	DELETE  /索引库名/_doc/文档id

示例： DELETE /heima/_doc/1 

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410185759.png)

#### 修改文档

​	我又新增了一个id为1的文档为：

```json
POST /heima/_doc/1
{
    "info": "黑马程序员Java讲师",
    "email": "zy@itcast.cn",
    "name": {
    "firstName":"云",
    "lastName":"陈"
	}
}
```

​	修改文档有两种方式：

1.全量修改，会删除旧文档，添加新文档

```json
PUT /索引库名/_doc/文档id
{
    "字段1": "值1",
    "字段2": "值2",
    // ... 略
}
```

实例：

```json
PUT /heima/_doc/1
{
    "info": "黑马程序员高级Java讲师",
    "email": "zy@itcast.cn",
    "name": {
        "firstName": "云",
        "lastName": "赵"
    }
}
```

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410190350.png)

注意：如果要修改的文档不存在，那么PUT命令就会新增一个文档



2.增量修改，修改指定字段值

```json
POST /索引库名/_update/文档id
{
    "doc": {
         "字段名": "新的值",
    }
}
```

实例：

```json
POST /heima/_update/1
{
  "doc": {
    "email": "ZhaoYun@qq.com"
  }
}
```

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410190621.png)

注意点：如果新增文档结构与mapping结果不一致，会报如下错：![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410190823.png)

## RestClient

​	ES官方提供了各种不同语言的客户端，用来操作ES。这些客户端的本质就是组装DSL语句，通过http请求发送给ES。官方文档地址：https://www.elastic.co/guide/en/elasticsearch/client/index.html



### 操作索引库

案例：利用JavaRestClient实现创建、删除索引库，判断索引库是否存在

根据课前资料提供的酒店数据创建索引库，索引库名为hotel，mapping属性根据数据库结构定义。

资料地址：https://wwz.lanzouj.com/iTKkC02yo87g  或者  http://gofile.me/6TtvQ/yP7pExd2U

基本步骤如下：

​	1.导入课前资料Demo

​			（1）先导入sql文件，新创一个数据库名叫heima，接着在heima数据库下执行tb_hotel.sql，数据库的结构如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410194013.png)

​			（2）用idea打开hotel-demo项目文件夹

​	2.分析数据结构，定义mapping属性

​				（1）需要考虑字段名、数据类型、是否参与搜索、是否分词、如果分词，分词器是什么？

```json
#酒店的mapping
PUT /hotel
{
  "mappings": {
    "properties": {
      "id":{
        "type": "keyword"
      },
      "name":{
        "type": "text",
        "analyzer": "ik_max_word",
        "copy_to": "all"
      },
      "address":{
        "type": "keyword",
        "index": false
      },
      "price":{
        "type": "integer"
      },
      "score":{
        "type": "integer"
      },
      "brand":{
        "type": "keyword",
        "copy_to": "all"
      },
      "city":{
        "type": "keyword"
      },
      "star_name":{
        "type": "keyword"
      },
      "business":{
        "type": "keyword",
        "copy_to": "all"
      },
      "location":{
        "type": "geo_point"
      },
      "pic":{
        "type": "keyword",
        "index": false
      },
      "all":{
        "type": "text",
        "analyzer": "ik_max_word"
      }
    }
  }
}
```

​	这里把经纬度合在一起成为一个整体，使用了es中的geo_point类型（ES中支持两种地理坐标数据类型：①•geo_point：由纬度（latitude）和经度（longitude）确定的一个点。例如："32.8752345,120.2981576"②有多个geo_point组成的复杂几何图形。例如一条直线，"LINESTRING (-77.03653 38.897676, -77.009051 38.889939)"）。

​	同时还是用了copy_to，将多个字段拷贝到指定字段，然后对指定字段创建倒排索引，这样在多条件查询下就会快一些，可以想成复合索引。

​	3.初始化JavaRestClient

​		（1）引入es的RestHighLevelClient依赖：

```xml
<dependency>
    <groupId>org.elasticsearch.client</groupId>
    <artifactId>elasticsearch-rest-high-level-client</artifactId>
</dependency>
```

​		（2）因为SpringBoot默认的ES版本是7.6.2，所以我们需要覆盖默认的ES版本：

```xml
<properties>
    <java.version>1.8</java.version>
    <elasticsearch.version>7.12.1</elasticsearch.version> 
</properties>
```

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410200238.png)

​			（3）初始化RestHighLevelClient：

​						可以在test文件夹下，新创建一个HotelIndexTest的测试类

```java
public class HotelIndexTest {
    private RestHighLevelClient client;
    @Test
    void testInit(){System.out.println(client);}
    @BeforeEach//在一开始就完成对象的初始化
    void setUp(){
        this.client = new RestHighLevelClient(RestClient.builder(
                HttpHost.create("http://192.168.10.130:9200")
        ));
    }
    @AfterEach//销毁对象
    void tearDown() throws IOException {this.client.close();}
}
```

​					打印的RestHighLevelClient如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410201013.png)



​	4.利用JavaRestClient创建索引库	

​	![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410201153.png)

```java
    @Test
    void createHotelIndex() throws IOException {
        //1.创建Request对象
        CreateIndexRequest request = new CreateIndexRequest("hotel");
        //2.准备请求的参数（即DSL语句）
        request.source(MAPPING_TEMPLATE, XContentType.JSON);//这里我把json语句存到常量里了
        //3.发送请求
        client.indices().create(request, RequestOptions.DEFAULT);
    }
```



​	5.利用JavaRestClient删除索引库

```java
    @Test
    void testDeleteHotelIndex() throws IOException {
        //1.创建Request对象
        DeleteIndexRequest request=new DeleteIndexRequest("hotel");
        //2.发起请求
        client.indices().delete(request,RequestOptions.DEFAULT);
    }
```

​	

​	6.利用JavaRestClient判断索引库是否存在

```java
    @Test
    void testExistsHotelIndex() throws IOException {
        //1.创建Request对象
        GetIndexRequest request = new GetIndexRequest("hotel");
        //2.发起请求
        boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);
        System.out.println(exists);
    }
```

### 操作文档

​	利用JavaRestClient实现文档的CRUD，去数据库查询酒店数据，导入到hotel索引库，实现酒店数据的CRUD。基本步骤如下：

​	1.初始化JavaRestClient，与操作索引库类似，略

​	2.利用JavaRestClient新增酒店数据到索引库，与DSL语法对应，很好理解

```java
@Test
void testIndexDocument() throws IOException {
    // 1.创建request对象 
    IndexRequest request = new IndexRequest("indexName").id("1");
    // 2.准备JSON文档
    request.source("{\"name\": \"Jack\", \"age\": 21}", XContentType.JSON);
    // 3.发送请求
    client.index(request, RequestOptions.DEFAULT);
}
```

​	在本案例中使用如下：

```java
@Test
void testIndexDocument() throws IOException {
    Hotel hotel = hotelService.getById(61083L); //根据id查询酒店数据
    HotelDoc hotelDoc=new HotelDoc(hotel);//转换为文档类型
    // 1.创建request对象
    IndexRequest request = new IndexRequest("hotel").id(hotel.getId().toString());
    // 2.准备JSON文档
    request.source(JSON.toJSONString(hotelDoc), XContentType.JSON);
    // 3.发送请求
    client.index(request,RequestOptions.DEFAULT);
}
```

​	3.利用JavaRestClient根据id查询酒店数据

```java
@Test
void testGetDocumentById() throws IOException {
    // 1.创建request对象
    GetRequest request = new GetRequest("hotel", "61083");
    // 2.发送请求，得到结果
    GetResponse response = client.get(request, RequestOptions.DEFAULT);
    // 3.解析结果
    String json = response.getSourceAsString();
    System.out.println(json);
}
```

​	4.利用JavaRestClient删除酒店数据

```java
@Test
void testDeleteDocumentById() throws IOException {
    // 1.创建request对象
    DeleteRequest request = new DeleteRequest("hotel", "61083");
    // 2.删除文档 
    client.delete(request, RequestOptions.DEFAULT);
}
```

​	5.利用JavaRestClient修改酒店数据

​		(1)全量更新。再次写入id一样的文档，就会删除旧文档，添加新文档

​		(2)局部更新。只更新部分字段，我们演示方式二

```java
@Test
void testUpdateDocumentById() throws IOException {
    // 1.创建request对象
    UpdateRequest request = new UpdateRequest("hotel", "61083");
    // 2.准备参数，每2个参数为一对 key value
    request.doc(
        "price", "666 "
    );
    // 3.更新文档
    client.update(request, RequestOptions.DEFAULT);
}
```

------

批量导入酒店数据到ES

需求：批量查询酒店数据，然后批量导入索引库中

思路：

1.利用mybatis-plus查询酒店数据

2.将查询到的酒店数据（Hotel）转换为文档类型数据（HotelDoc）

3.利用JavaRestClient中的Bulk批处理，实现批量新增文档，示例代码如下

```java
@Test
void testBulkRequest() throws IOException {
    //1.创建Request
    BulkRequest request=new BulkRequest();
    //批量查询酒店数据
    List<Hotel> hotels = hotelService.list();
    //2.准备参数，准备多个新增的Request
    for(Hotel hotel:hotels){
        //转换为文档类HotelDoc
        HotelDoc hotelDoc=new HotelDoc(hotel);
        //创建新增文档的Request对象
        request.add(new IndexRequest("hotel")
                .id(hotelDoc.getId().toString())
                .source(JSON.toJSONString(hotelDoc),XContentType.JSON));
    }
    //3.最后集体发送Bulk的Request请求
    client.bulk(request,RequestOptions.DEFAULT);
}
```

​	然后在浏览器使用批量查询（GET /hotel/_search），结果如下：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410215036.png)

## DSL查询文档

### DSL Query的分类

​	Elasticsearch提供了基于JSON的DSL（[Domain Specific Language](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html)）来定义查询。常见的查询类型包括：

​	1.查询所有：查询出所有数据，一般测试用。例如：match_all。一般不会查所有出来，可能会给你分页，一次查20个出来

​	2.全文检索（full text）查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：（1）match_query （2）multi_match_query

​	3.精确查询：根据精确词条值查找数据，一般是查找keyword、数值、日期、boolean等类型字段。例如：(1)ids，根据id精确匹配 (2)range，在数值一定范围内查询(3)term，按照数据的值查询

​	4.地理（geo）查询：根据经纬度查询。例如：(1)geo_distance (2)geo_bounding_box

​	5.复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：（1）bool (2)function_score

### 语法

​	查询的基本语法如下：

```json
GET /indexName/_search
{
  "query": {
    "查询类型": {
      "查询条件": "条件值"
    }
  }
}
```

​	查询所有，默认一次返回十条数据：

![](https://cdn.jsdelivr.net/gh/SiQuan77/img_bed/20220410221956.png)
